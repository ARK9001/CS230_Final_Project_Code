{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230-Final-Deep-Fashion-GAN-Lookbook-Submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5AKvwtLmIEB",
        "colab_type": "text"
      },
      "source": [
        "# ***CS 230 DEEP LEARNING FASHION OUTFIT LOOKBOOK [CODE]***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYZBY6XK2hB0",
        "colab_type": "text"
      },
      "source": [
        "***Author:*** Aishwarya Rameshkumar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uXsdufusA-q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "***Overview:*** \n",
        "The fashion and design industry is a globally-encompassing \\$2.4 trillion dollar industry which has been around for centuries; however, throughout this time, the traditional approach to design with human designers has largely stayed the same. With recent advancements, we now have the opportunity to utilize strides in deep learning to rethink the approach to fashion design and generation. This project explore the use of DCGANs as well as other deep learning techniques such as ANN Classifiers in the exploration and generation of new fashion outfit looks. The final deliverable is an end-to-end pipeline including GAN/Classifier models, analysis modules, and more which encompasses the entire machine learning cycle and results in generated clothing images near state-of-the-art image quality and the generation of a new model-based fashion outfit for a lookbook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BUnvgTHmr-v",
        "colab_type": "text"
      },
      "source": [
        "## **I. PRELIMINARY SETUP AND IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwooJf5uivi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGHWo7mi6qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gdrive/My Drive/CS230/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94GCgxTEi9Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import os\n",
        "from glob import glob\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wzDPWxYOnAxn"
      },
      "source": [
        "## **II. DCGAN RELATED FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlxUOWX2jLiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(z, output_channel_dim, training):\n",
        "    with tf.variable_scope(\"generator\", reuse= not training):\n",
        "        \n",
        "        # 8x8x1024\n",
        "        fully_connected = tf.layers.dense(z, 8*8*1024)\n",
        "        fully_connected = tf.reshape(fully_connected, (-1, 8, 8, 1024))\n",
        "        fully_connected = tf.nn.leaky_relu(fully_connected)\n",
        "\n",
        "        # 8x8x1024 -> 16x16x512\n",
        "        trans_conv1 = tf.layers.conv2d_transpose(inputs=fully_connected,\n",
        "                                                 filters=512,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv1\")\n",
        "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv1\")\n",
        "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1,\n",
        "                                           name=\"trans_conv1_out\")\n",
        "        \n",
        "        # 16x16x512 -> 32x32x256\n",
        "        trans_conv2 = tf.layers.conv2d_transpose(inputs=trans_conv1_out,\n",
        "                                                 filters=256,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv2\")\n",
        "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv2\")\n",
        "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2,\n",
        "                                           name=\"trans_conv2_out\")\n",
        "        \n",
        "        # 32x32x256 -> 64x64x128\n",
        "        trans_conv3 = tf.layers.conv2d_transpose(inputs=trans_conv2_out,\n",
        "                                                 filters=128,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv3\")\n",
        "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv3\")\n",
        "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3,\n",
        "                                           name=\"trans_conv3_out\")\n",
        "        \n",
        "        # 64x64x128 -> 128x128x64\n",
        "        trans_conv4 = tf.layers.conv2d_transpose(inputs=trans_conv3_out,\n",
        "                                                 filters=64,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv4\")\n",
        "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv4\")\n",
        "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4,\n",
        "                                           name=\"trans_conv4_out\")\n",
        "        \n",
        "        # 128x128x64 -> 128x128x3\n",
        "        logits = tf.layers.conv2d_transpose(inputs=trans_conv4_out,\n",
        "                                            filters=3,\n",
        "                                            kernel_size=[5,5],\n",
        "                                            strides=[1,1],\n",
        "                                            padding=\"SAME\",\n",
        "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                            name=\"logits\")\n",
        "        out = tf.tanh(logits, name=\"out\")\n",
        "        return out\n",
        "\n",
        "def discriminator(x, reuse):\n",
        "    with tf.variable_scope(\"discriminator\", reuse=reuse): \n",
        "        \n",
        "        # 128*128*3 -> 64x64x64 \n",
        "        conv1 = tf.layers.conv2d(inputs=x,\n",
        "                                 filters=64,\n",
        "                                 kernel_size=[5,5],\n",
        "                                 strides=[2,2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv1')\n",
        "        batch_norm1 = tf.layers.batch_normalization(conv1,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm1')\n",
        "        conv1_out = tf.nn.leaky_relu(batch_norm1,\n",
        "                                     name=\"conv1_out\")\n",
        "        \n",
        "        # 64x64x64-> 32x32x128 \n",
        "        conv2 = tf.layers.conv2d(inputs=conv1_out,\n",
        "                                 filters=128,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[2, 2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv2')\n",
        "        batch_norm2 = tf.layers.batch_normalization(conv2,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm2')\n",
        "        conv2_out = tf.nn.leaky_relu(batch_norm2,\n",
        "                                     name=\"conv2_out\")\n",
        "        \n",
        "        # 32x32x128 -> 16x16x256  \n",
        "        conv3 = tf.layers.conv2d(inputs=conv2_out,\n",
        "                                 filters=256,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[2, 2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv3')\n",
        "        batch_norm3 = tf.layers.batch_normalization(conv3,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm3')\n",
        "        conv3_out = tf.nn.leaky_relu(batch_norm3,\n",
        "                                     name=\"conv3_out\")\n",
        "        \n",
        "        # 16x16x256 -> 16x16x512\n",
        "        conv4 = tf.layers.conv2d(inputs=conv3_out,\n",
        "                                 filters=512,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[1, 1],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv4')\n",
        "        batch_norm4 = tf.layers.batch_normalization(conv4,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm4')\n",
        "        conv4_out = tf.nn.leaky_relu(batch_norm4,\n",
        "                                     name=\"conv4_out\")\n",
        "        \n",
        "        # 16x16x512 -> 8x8x1024\n",
        "        conv5 = tf.layers.conv2d(inputs=conv4_out,\n",
        "                                filters=1024,\n",
        "                                kernel_size=[5, 5],\n",
        "                                strides=[2, 2],\n",
        "                                padding=\"SAME\",\n",
        "                                kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                name='conv5')\n",
        "        batch_norm5 = tf.layers.batch_normalization(conv5,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm5')\n",
        "        conv5_out = tf.nn.leaky_relu(batch_norm5,\n",
        "                                     name=\"conv5_out\")\n",
        "\n",
        "        flatten = tf.reshape(conv5_out, (-1, 8*8*1024))\n",
        "        logits = tf.layers.dense(inputs=flatten,\n",
        "                                 units=1,\n",
        "                                 activation=None)\n",
        "        out = tf.sigmoid(logits)\n",
        "        return out, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBqg0yXPjQFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_loss(input_real, input_z, output_channel_dim):\n",
        "    g_model = generator(input_z, output_channel_dim, True)\n",
        "\n",
        "    noisy_input_real = input_real + tf.random_normal(shape=tf.shape(input_real),\n",
        "                                                     mean=0.0,\n",
        "                                                     stddev=random.uniform(0.0, 0.1),\n",
        "                                                     dtype=tf.float32)\n",
        "    \n",
        "    d_model_real, d_logits_real = discriminator(noisy_input_real, reuse=False)\n",
        "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
        "    \n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
        "                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                         labels=tf.zeros_like(d_model_fake)))\n",
        "    d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                    labels=tf.ones_like(d_model_fake)))\n",
        "    return d_loss, g_loss\n",
        "\n",
        "def model_optimizers(d_loss, g_loss):\n",
        "    t_vars = tf.trainable_variables()\n",
        "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
        "    \n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n",
        "    \n",
        "    with tf.control_dependencies(gen_updates):\n",
        "        d_train_opt = tf.train.AdamOptimizer(learning_rate=LR_D, beta1=BETA1).minimize(d_loss, var_list=d_vars)\n",
        "        g_train_opt = tf.train.AdamOptimizer(learning_rate=LR_G, beta1=BETA1).minimize(g_loss, var_list=g_vars)  \n",
        "    return d_train_opt, g_train_opt\n",
        "\n",
        "def model_inputs(real_dim, z_dim):\n",
        "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
        "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
        "    learning_rate_G = tf.placeholder(tf.float32, name=\"lr_g\")\n",
        "    learning_rate_D = tf.placeholder(tf.float32, name=\"lr_d\")\n",
        "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQO4pt2jQHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(sess, input_z, out_channel_dim, epoch):\n",
        "    example_z = np.random.uniform(-1, 1, size=[SAMPLES_TO_SHOW, input_z.get_shape().as_list()[-1]])\n",
        "    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n",
        "    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
        "    show_samples(sample_images, OUTPUT_DIR_GAN + \"samples\", epoch)\n",
        "\n",
        "def summarize_epoch(epoch, duration, sess, d_losses, g_losses, input_z, data_shape):\n",
        "    minibatch_size = int(data_shape[0]//BATCH_SIZE)\n",
        "    print(\"Epoch {}/{}\".format(epoch, EPOCHS),\n",
        "          \"\\nDuration: {:.5f}\".format(duration),\n",
        "          \"\\nD Loss: {:.5f}\".format(np.mean(d_losses[-minibatch_size:])),\n",
        "          \"\\nG Loss: {:.5f}\".format(np.mean(g_losses[-minibatch_size:])))\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
        "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
        "    plt.title(\"Losses\")\n",
        "    plt.legend()\n",
        "    plt.savefig(OUTPUT_DIR_GAN + \"losses_\" + str(epoch) + \".png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    test(sess, input_z, data_shape[3], epoch)\n",
        "\n",
        "def get_batches(data):\n",
        "    batches = []\n",
        "    for i in range(int(data.shape[0]//BATCH_SIZE)):\n",
        "        batch = data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "        augmented_images = []\n",
        "        for img in batch:\n",
        "            image = Image.fromarray(img)\n",
        "            if random.choice([True, False]):\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            augmented_images.append(np.asarray(image))\n",
        "        batch = np.asarray(augmented_images)\n",
        "        normalized_batch = (batch / 127.5) - 1.0\n",
        "        batches.append(normalized_batch)\n",
        "    return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2YX2pbjQMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(get_batches, data_shape, checkpoint_to_load=None):\n",
        "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], NOISE_SIZE)\n",
        "    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3])\n",
        "    d_opt, g_opt = model_optimizers(d_loss, g_loss)\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    sess = tf.Session()\n",
        "    if checkpoint_to_load:\n",
        "      print(\"Loading checkpoint model\")\n",
        "      saved_location =  CHECKPOINT_DIR + CHECKPOINT_META_FILE\n",
        "      saved_model = tf.train.import_meta_graph(saved_location)\n",
        "      saved_model.restore(sess,tf.train.latest_checkpoint(CHECKPOINT_DIR))\n",
        "    else:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "    epoch = 0\n",
        "    iteration = 0\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "        \n",
        "    for epoch in range(EPOCHS):        \n",
        "        epoch += 1\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_images in get_batches:\n",
        "            iteration += 1\n",
        "            batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_SIZE))\n",
        "            _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: LR_D})\n",
        "            _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: LR_G})\n",
        "            d_losses.append(d_loss.eval(feed_dict={input_z: batch_z, input_images: batch_images}, session=sess))\n",
        "            g_losses.append(g_loss.eval(feed_dict={input_z: batch_z}, session=sess))\n",
        "\n",
        "        summarize_epoch(epoch, time.time()-start_time, sess, d_losses, g_losses, input_z, data_shape)\n",
        "\n",
        "        if epoch%5 == 0:\n",
        "          savepath = MODEL_SAVE_DIR + 'model_checkpoint_epoch_' + str(epoch) \n",
        "          saver.save(sess, savepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCi2S72IjQJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_samples(sample_images, name, epoch):\n",
        "    figure, axes = plt.subplots(1, len(sample_images), figsize = (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    for index, axis in enumerate(axes):\n",
        "        axis.axis('off')\n",
        "        image_array = sample_images[index]\n",
        "        axis.imshow(image_array)\n",
        "        image = Image.fromarray(image_array)\n",
        "        image.save(name+\"_\"+str(epoch)+\"_\"+str(index)+\".png\") \n",
        "    plt.savefig(name+\"_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6i_W_f3NL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Referenced code: https://github.com/gsurma/image_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Dhls_FAnbCY"
      },
      "source": [
        "## **II. ANN/CLASSIFIER RELATED FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBuhMY43jQOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_labels(input_dir, annos, names2labels_dict):\n",
        "  labels_df = pd.DataFrame(columns = [\"image id\", \"category\", \"category_label\"])\n",
        "  for file in glob(input_dir + '*'):\n",
        "    image_file = file.split(sep=\"/\")\n",
        "    image_id = image_file[2].split(sep=\".\")[0]\n",
        "    category = annos.loc[annos.id == int(image_id), ['articleType']].values.tolist()[0][0]\n",
        "    category_label = names2labels_dict[category]\n",
        "    labels_df = labels_df.append({\"image id\": image_id, \"category\": category, \"category_label\": category_label}, ignore_index=True)\n",
        "  final_labels = labels_df[\"category_label\"].to_numpy()\n",
        "  print(labels_df.head())\n",
        "  return labels_df, final_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fru2NETwjQ3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'green'\n",
        "    plt.xlabel(\"{}\".format(category_labels2names_dict[predicted_label]),\n",
        "                                color=color)\n",
        "  else:\n",
        "    color = 'red'\n",
        "    plt.xlabel(\"{} ({})\".format(category_labels2names_dict[predicted_label],\n",
        "                                category_labels2names_dict[true_label]),\n",
        "                                color=color)\n",
        "  \n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  thisplot = plt.scatter([i for i in range(len(predictions_array))], predictions_array, color=\"#777777\");\n",
        "  max_value_point = np.argmax(predictions[i])\n",
        "  thisplot = plt.scatter([true_label], predictions_array[true_label], color='r');\n",
        "  thisplot = plt.scatter([max_value_point], predictions_array[max_value_point], color='g');\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3pzxtA83SCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Referenced code tutorial: https://www.tensorflow.org/tutorials/keras/classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OPMmnKkDoOpo"
      },
      "source": [
        "## **IV. MAIN INPUT INITIALIZATION AND DIRECTORY SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UP4SX5cjQQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paths to images and directory setup\n",
        "INPUT_DATA_DIR = \"fashion_images_s/images/\" #Input images folder\n",
        "INPUT_DATA_DIR_TEST = \"fashion_images_s/images_test/\" #Input images test set folder \n",
        "INPUT_ANNO_PATH = \"fashion_images_s/styles.csv\" #Input images csv with annotations of image category, style, etc.\n",
        "\n",
        "#Output directories to save files for experiment\n",
        "OUTPUT_DIR = './final_test_output_2/'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "OUTPUT_DIR_GAN = OUTPUT_DIR + \"gan/\"\n",
        "if not os.path.exists(OUTPUT_DIR_GAN):\n",
        "    os.makedirs(OUTPUT_DIR_GAN)\n",
        "\n",
        "OUTPUT_DIR_CNN = OUTPUT_DIR + \"cnn/\"\n",
        "if not os.path.exists(OUTPUT_DIR_CNN):\n",
        "    os.makedirs(OUTPUT_DIR_CNN)\n",
        "\n",
        "MODEL_SAVE_DIR = OUTPUT_DIR + 'models/'\n",
        "if not os.path.exists(MODEL_SAVE_DIR):\n",
        "    os.makedirs(MODEL_SAVE_DIR)\n",
        "\n",
        "#Point to file to load if input images were already processed and saved\n",
        "LOAD_SAVED_IMAGES = True\n",
        "INPUT_IMAGES_SAVED_PATH = 'fashion_images_s/images_input_images_saved.npy'\n",
        "TEST_IMAGES_SAVED_PATH = 'fashion_images_s/images_test_images_saved.npy'\n",
        "\n",
        "#Point to checkpoint to resume model training from \n",
        "LOAD_CHECKPOINT = False\n",
        "CHECKPOINT_DIR = './ark_test_output_5_3_models/'\n",
        "CHECKPOINT_META_FILE = 'model_save_test_epoch_10.meta'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5O4Ucyeo2i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters Initialization\n",
        "IMAGE_SIZE = 128\n",
        "NOISE_SIZE = 95\n",
        "LR_D = 0.0001\n",
        "LR_G = 0.0001\n",
        "LR_CNN = 0.0001\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 300\n",
        "BETA1 = 0.3\n",
        "WEIGHT_INIT_STDDEV = 0.02\n",
        "EPSILON = 0.000008\n",
        "SAMPLES_TO_SHOW = 5\n",
        "EPOCHS_CNN = 300\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhncjNDSjQV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input images processing/loading \n",
        "if LOAD_SAVED_IMAGES == True:\n",
        "  print(\"Loading processed images...\")\n",
        "  input_images = np.load(INPUT_IMAGES_SAVED_PATH)\n",
        "  input_images_cnn = copy.deepcopy(input_images)\n",
        "  test_images = np.load(TEST_IMAGES_SAVED_PATH)\n",
        "else:\n",
        "  print(\"Processing images...\")\n",
        "  input_images = np.asarray([np.asarray(Image.open(file).convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_DATA_DIR + '*')])\n",
        "  input_images_cnn = copy.deepcopy(input_images)\n",
        "  test_images = np.asarray([np.asarray(Image.open(file).convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_DATA_DIR_TEST + '*')])\n",
        "\n",
        "print (\"Input Sample: \")\n",
        "\n",
        "if not os.path.exists(INPUT_IMAGES_SAVED_PATH):\n",
        "  np.save(INPUT_IMAGES_SAVED_PATH, input_images)\n",
        "  print(\"Processed images array saved.\")\n",
        "if not os.path.exists(TEST_IMAGES_SAVED_PATH):\n",
        "  np.save(TEST_IMAGES_SAVED_PATH, test_images)\n",
        "  print(\"Processed test images array saved.\")\n",
        "\n",
        "np.random.shuffle(input_images)\n",
        "\n",
        "np.seterr('raise')\n",
        "\n",
        "sample_images = random.sample(list(input_images), SAMPLES_TO_SHOW)\n",
        "show_samples(sample_images, OUTPUT_DIR_GAN + \"inputs\", 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tD_0aesQp1WW"
      },
      "source": [
        "## **V. ANN/CLASSIFIER MODEL SETUP/TRAINING/TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqJmBJp-jQdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parse labels for classifier\n",
        "annotations = pd.read_csv(INPUT_ANNO_PATH)  \n",
        "annotations = annotations.drop(columns=['Unnamed: 10', 'Unnamed: 11']).sort_values(by=['id'])\n",
        "\n",
        "category_names = annotations.articleType.unique().tolist()\n",
        "category_names2labels_dict = {}\n",
        "count = 0\n",
        "for i, c in enumerate(category_names):\n",
        "  category_names2labels_dict[c] = i\n",
        "category_labels2names_dict = {value : key for (key, value) in category_names2labels_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um_88lWFu7jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Z0vmBcvFmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot distribution of article type\n",
        "p = annotations.articleType.value_counts()\n",
        "p.plot(kind='bar', title=\"Article Type vs. Counts\")\n",
        "annotations.articleType.value_counts()\n",
        "\n",
        "count=0\n",
        "for i in range(p.shape[0]):\n",
        "  if p[i] >= 1000:\n",
        "    count = count + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlheJ8qVucff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate image labels for train and test sets\n",
        "train_labels_df, input_images_labels = parse_labels(INPUT_DATA_DIR, annotations, category_names2labels_dict)\n",
        "test_labels_df, test_images_labels = parse_labels(INPUT_DATA_DIR_TEST, annotations, category_names2labels_dict)\n",
        "input_images_cnn = input_images_cnn / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYIptBswjQvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot sample of train images with corresponding label to verify\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(input_images_cnn[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(category_labels2names_dict[input_images_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K4LCNUyjQx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(128, 128, 3)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(len(category_names))\n",
        "])\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=LR_CNN)\n",
        "model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(input_images_cnn, input_images_labels, epochs=EPOCHS_CNN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfc0wuu2jQ0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_images_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "print(predictions[0])\n",
        "print(np.argmax(predictions[0]))\n",
        "print(test_images_labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOcVrF6jQ55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted label, and the next highest prob label\n",
        "num_rows = 2\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "idx_plotted = []\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  idx = random.choice([x for x in range(len(test_images))])\n",
        "  while (idx in idx_plotted):\n",
        "    idx = random.choice([x for x in range(len(test_images))])\n",
        "  plot_image(idx, predictions[idx], test_images_labels, test_images)\n",
        "  idx_plotted.append(idx)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vqax2aJqqbnT"
      },
      "source": [
        "## **VI. DCGAN MODEL SETUP/TRAINING/IMAGE GENERATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQImjq3rjQYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRAIN DCGAN AND GENERATE IMAGES\n",
        "with tf.Graph().as_default():\n",
        "    train(get_batches(input_images), input_images.shape, checkpoint_to_load = LOAD_CHECKPOINT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HXqzQZuSqoWe"
      },
      "source": [
        "## **VII. PREDICTION/CLASSIFICATION OF GAN GENERATED IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VKxiFmkjQ_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Process GAN generated images into correct format and predict category labels\n",
        "\n",
        "INPUT_GAN_IMAGES = \"./ark_test_output_5_3/\" #OUTPUT_DIR_GAN\n",
        "\n",
        "print(\"Processing images...\")\n",
        "input_gan_images = np.asarray([np.asarray(Image.open(file).convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_GAN_IMAGES + '*') if re.search(\"samples_\\d+_\", file)])\n",
        "\n",
        "print (\"Input: \" + str(input_gan_images.shape))\n",
        "\n",
        "sample_images = random.sample(list(input_gan_images), SAMPLES_TO_SHOW)\n",
        "show_samples(sample_images, \"classification_test_output_1/\", 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw4zbFUncz8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan_images_predictions = probability_model.predict(input_gan_images)\n",
        "print(gan_images_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0O95nSXdQbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image_gan(i, predictions_array, img):\n",
        "  predictions_array, img = predictions_array, img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  \n",
        "  color = 'blue'\n",
        "  plt.xlabel(\"{}\".format(category_labels2names_dict[predicted_label]),\n",
        "                                color=color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWdooquOdkmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image_gan(i, gan_images_predictions[i], input_gan_images)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "41wV_unvq8fU"
      },
      "source": [
        "## **VIII. FINAL OUTFIT PAIRING AND LOOKBOOK RECOMMENDATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWJUtTeOjQnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_category_img(images, predictions):\n",
        "  category_img_dict = {}\n",
        "  for i in range(len(images)):\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    category_label = category_labels2names_dict[predicted_label]\n",
        "    if category_label in category_img_dict:\n",
        "      category_img_dict[category_label].append(i)\n",
        "    else:\n",
        "      category_img_dict[category_label] = [i]\n",
        "\n",
        "  return category_img_dict\n",
        "\n",
        "gan_category_images = get_category_img(input_gan_images, gan_images_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIRDuy79GyOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairings = [['Shirts', 'Jeans', 'Sports Shoes', 'Wallets'],\n",
        "            ['Sweaters', 'Trousers', 'Casual Shoes', 'Watches'],\n",
        "            ['Kurtas', 'Shorts', 'Heels', 'Belts'],\n",
        "            ['Dresses', 'Heels', 'Handbags', 'Scarves'],\n",
        "            ['Tshirts', 'Jeans', 'Jackets', 'Casual Shoes'],\n",
        "            ['Sweaters', 'Shorts', 'Jackets', 'Sports Shoes', 'Caps'],\n",
        "            ['Tops', 'Jeans', 'Casual Shoes', 'Backpacks', 'Belts'],\n",
        "            ['Sweatshirts', 'Shorts', 'Sports Shoes', 'Sunglasses', 'Waist Pouch'],\n",
        "            ['Shirts', 'Trunk', 'Innerwear Vests', 'Wallets', 'Casual Shoes'],\n",
        "            ['Tshirts', 'Shorts', 'Heels', 'Handbags'],\n",
        "            ['Kurtis', 'Heels', 'Handbags']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfRRcuSIJJWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_new_look(images, category_images):\n",
        "  final_pairing = []\n",
        "  final_pairing_categories = []\n",
        "  pairing = random.choice(pairings)\n",
        "  for item in pairing:\n",
        "    image_ind = random.choice(category_images[item])\n",
        "    final_pairing.append(images[image_ind])\n",
        "    final_pairing_categories.append(item)\n",
        "  return final_pairing, final_pairing_categories\n",
        "\n",
        "def plot_final_outfit(i, images, images_categories):\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "  color = 'blue'\n",
        "  plt.xlabel(\"{}\".format(images_categories[i]), color=color)\n",
        "\n",
        "def show_final_outfit(images, images_categories):\n",
        "    figure, axes = plt.subplots(1, len(images), figsize = (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    for index, axis in enumerate(axes):\n",
        "        axis.axis('off')\n",
        "        image_array = images[index]\n",
        "        axis.imshow(image_array)\n",
        "        axis.set_title(\"{}\".format(images_categories[index]), fontsize=60) #.xlabel(\"{}\".format(images_categories[index]), color=color)\n",
        "        image = Image.fromarray(image_array)\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps9T89S4ONsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate 2 sample lookbook outfits\n",
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"-------------------------------------------------------------FINAL EXAMPLE LOOKBOOK OUTFIT: ---------------------------------------------------------------------------\")\n",
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "final_outfit, final_outfit_cat = generate_new_look(input_gan_images, gan_category_images)\n",
        "show_final_outfit(final_outfit, final_outfit_cat)\n",
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2d_ZZhh1FhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"-------------------------------------------------------------FINAL EXAMPLE LOOKBOOK OUTFIT: ---------------------------------------------------------------------------\")\n",
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
        "final_outfit, final_outfit_cat = generate_new_look(input_gan_images, gan_category_images)\n",
        "show_final_outfit(final_outfit, final_outfit_cat)\n",
        "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}